{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymtattl import MTADownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mta_downloader = MTADownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_downloader.download_to_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = mta_downloader.download_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Staion Name and Google Maps API to get latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.read_sql_query(\"select * from name_keys\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nk_append = [('R194','R217','BLEECKER ST','6DF','IRT'),\n",
    "             ('R001','R101','SOUTH FERRY','R1','IRT'),\n",
    "             ('R028','A077','FULTON ST','ACJZ2345','BMT'),\n",
    "             ('R028','A081','FULTON ST','ACJZ2345','BMT'),\n",
    "             ('R028','A082','FULTON ST','ACJZ2345','BMT'),\n",
    "             ('R088','A049','CORTLANDT ST','R','BMT'),\n",
    "             ('R057','R612','ATLANTIC AVE','2345BDNQR','IRT'),\n",
    "             ('R028','N098','FULTON ST','2345ACJZ','IRT'),\n",
    "             ('R202','N330','63 DR-REGO PARK','MR','IND'),\n",
    "             ('R168','R169','96 ST','123','IRT'),\n",
    "             ('R014','N095A','FULTON ST','ACJZ2345','IND')]\n",
    "\n",
    "def append_name_key(db_path, new_nk):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.executemany('INSERT INTO name_keys VALUES '\n",
    "              '(?,?,?,?,?)', new_nk)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_name_key(db_path, nk_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "import json\n",
    "\n",
    "GEOCODING_ENDPOINT = 'https://maps.googleapis.com/maps/api/geocode/json?address='\n",
    "\n",
    "# metrocard vans could be ignored as no turnstile data and doesn't sound like going to have any\n",
    "# newark hw bmebe, newark bm bw, newark hm he no idea\n",
    "miss_station_dict = {\n",
    "    \"2 BDWY CUST SRV\":\"2 Broadway\",\n",
    "    \"8 ST-B'WAY NYU\":\"East 8th Street & Broadway\",\n",
    "    \"HOYT/SCHERMER\":\"Hoyt Street & Schermerhorn Street\",\n",
    "    \"MURRAY ST-B'WAY\":\"Broadway/Murray St\",\n",
    "    \"PRINCE ST-B'WAY\":\"Broadway/Prince St\"\n",
    "}\n",
    "\n",
    "def search_geocoding(name):\n",
    "    full = name.replace(\" \",\"+\") + \",+New+York\"\n",
    "    req = GEOCODING_ENDPOINT + full + \"&key=\" + GEOCODING_API_KEY\n",
    "    data = json.load(urlopen(req))\n",
    "    return data['results'][0]['geometry']['location']\n",
    "\n",
    "def locate_stations(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS geo_stations '\n",
    "              '(station text, lat real, lng real)')\n",
    "    stations = pd.read_sql_query(\"select distinct station from name_keys\", conn)['station']\n",
    "    exist_stations = pd.read_sql_query(\"select distinct station from geo_stations\", conn)['station']\n",
    "    new_set = set(stations)-set(exist_stations)\n",
    "    new_stations = {}\n",
    "    miss_stations = []\n",
    "    j = 0\n",
    "    for s in new_set:\n",
    "        try:\n",
    "            new_stations[s] = search_geocoding(s)\n",
    "        except HTTPError as he:\n",
    "            print(he)\n",
    "            conn.close()\n",
    "            raise\n",
    "        except IndexError as e:\n",
    "            if s in miss_station_dict.keys():\n",
    "                new_stations[s] = search_geocoding(miss_station_dict[s])\n",
    "            else:\n",
    "                miss_stations.append(s)\n",
    "                continue\n",
    "        j+=1\n",
    "        if j % 20 == 0:\n",
    "            print(\"Searching {} stations...\".format(j))\n",
    "    df = pd.DataFrame.from_dict(new_stations, orient='index').reset_index()\n",
    "    df.rename(index=str, columns={\"index\":\"station\"}, inplace=True)\n",
    "    df.to_sql('geo_stations', con=conn, if_exists='append', index=False)\n",
    "    conn.close()\n",
    "    print(\"Wrote {} out of {} new station locations to database\".format(j, len(new_set)))\n",
    "    return miss_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_stations = locate_stations(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Station Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START = \"2010-04-17\"\n",
    "END = \"2010-04-21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daily_station_summary(db_path, start, end, geo=True):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    QUERY_TEXT = \"select * from turnstiles where date >= '{}' and date <= '{}' and desc = 'REGULAR'\".format(start, end)\n",
    "    df = pd.read_sql_query(QUERY_TEXT, conn)\n",
    "    df_nk = pd.read_sql_query(\"select * from name_keys\", conn)\n",
    "    df_nk.drop(['line','division'], axis=1, inplace=True)\n",
    "    if geo:\n",
    "        df_geo = pd.read_sql_query(\"select * from geo_stations\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    # de-cumulate entry/exit numbers\n",
    "    df['datime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "    df.drop(['date','time','desc'], axis=1, inplace=True)\n",
    "    df.drop_duplicates(keep='first', inplace=True)\n",
    "    level = ['remote','booth','scp']\n",
    "    df = df.sort_values(by=level + ['datime']).reset_index(drop=True)\n",
    "    df['entry_diff'] = df.groupby(level)['entries'].diff()\n",
    "    df['exit_diff'] = df.groupby(level)['exits'].diff()\n",
    "    # might have negative values due to reasons ie. counter reset, etc.\n",
    "    # but there shouldn't be negative entries/exits, set to zero\n",
    "    df.loc[df['entry_diff'] < 0, 'entry_diff'] = 0\n",
    "    df.loc[df['exit_diff'] < 0, 'exit_diff'] = 0\n",
    "    df['date'] = df['datime'].dt.date\n",
    "    df.drop(['scp','entries','exits','datime'], axis=1, inplace=True)\n",
    "    \n",
    "    # get station name from name_keys table\n",
    "    df = df.merge(df_nk, how='inner', left_on=['booth','remote'], right_on=['booth','remote']).fillna(0)\n",
    "    df = df.groupby(['station','date'])['entry_diff','exit_diff'].sum().reset_index()\n",
    "    if geo:\n",
    "        df = df.merge(df_geo, how='inner', on='station')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = daily_station_summary(db_path, START, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>entry_diff</th>\n",
       "      <th>exit_diff</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AVE</td>\n",
       "      <td>2010-04-17</td>\n",
       "      <td>12441.0</td>\n",
       "      <td>14374.0</td>\n",
       "      <td>40.763368</td>\n",
       "      <td>-73.95924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AVE</td>\n",
       "      <td>2010-04-18</td>\n",
       "      <td>15255.0</td>\n",
       "      <td>17258.0</td>\n",
       "      <td>40.763368</td>\n",
       "      <td>-73.95924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AVE</td>\n",
       "      <td>2010-04-19</td>\n",
       "      <td>20346.0</td>\n",
       "      <td>22223.0</td>\n",
       "      <td>40.763368</td>\n",
       "      <td>-73.95924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AVE</td>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>23791.0</td>\n",
       "      <td>40.763368</td>\n",
       "      <td>-73.95924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AVE</td>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>21786.0</td>\n",
       "      <td>25174.0</td>\n",
       "      <td>40.763368</td>\n",
       "      <td>-73.95924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station        date  entry_diff  exit_diff        lat       lng\n",
       "0   1 AVE  2010-04-17     12441.0    14374.0  40.763368 -73.95924\n",
       "1   1 AVE  2010-04-18     15255.0    17258.0  40.763368 -73.95924\n",
       "2   1 AVE  2010-04-19     20346.0    22223.0  40.763368 -73.95924\n",
       "3   1 AVE  2010-04-20     21263.0    23791.0  40.763368 -73.95924\n",
       "4   1 AVE  2010-04-21     21786.0    25174.0  40.763368 -73.95924"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
